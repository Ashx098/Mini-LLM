# ğŸ§  Tokenizer Evaluation Report

Comparing **Unigram** vs **BPE (Byte Fallback)** Tokenizers.

---

## ğŸ” Tokenization Examples

### Input:
`Hello world! <user> write code </s>`

**Unigram:**
```
['H', 'ello', 'â–world', '!', 'â–', '<user>', 'â–write', 'â–code', 'â–', '</s>']
```

**BPE:**
```
['H', 'ello', 'â–world', '!', 'â–', '<user>', 'â–write', 'â–code', 'â–', '</s>']
```
---

### Input:
`myHTTPRequestHandler is calling process_payment_v2`

**Unigram:**
```
['my', 'HT', 'TP', 'Re', 'quest', 'H', 'and', 'ler', 'â–is', 'â–calling', 'â–process', '_', 'pay', 'ment', '_', 'v', '2']
```

**BPE:**
```
['my', 'H', 'T', 'T', 'PR', 'equ', 'est', 'H', 'and', 'ler', 'â–is', 'â–calling', 'â–process', '_', 'pay', 'ment', '_', 'v', '2']
```
---

### Input:
`methylphenidate hydrochloride dopamine reuptake modulation`

**Unigram:**
```
['m', 'ethyl', 'phen', 'id', 'ate', 'â–hydro', 'chlor', 'ide', 'â–dopamine', 'â–re', 'up', 'take', 'â–mod', 'ulation']
```

**BPE:**
```
['m', 'eth', 'yl', 'p', 'hen', 'id', 'ate', 'â–hydro', 'ch', 'lor', 'ide', 'â–dopamine', 'â–re', 'upt', 'ake', 'â–mod', 'ulation']
```
---

### Input:
`hello ğŸ”¥ğŸ”¥ğŸ”¥ğŸ’€ğŸ’€`

**Unigram:**
```
['h', 'ello', 'â–', 'ğŸ”¥ğŸ”¥ğŸ”¥ğŸ’€ğŸ’€']
```

**BPE:**
```
['hell', 'o', 'â–', '<0xF0>', '<0x9F>', '<0x94>', '<0xA5>', '<0xF0>', '<0x9F>', '<0x94>', '<0xA5>', '<0xF0>', '<0x9F>', '<0x94>', '<0xA5>', '<0xF0>', '<0x9F>', '<0x92>', '<0x80>', '<0xF0>', '<0x9F>', '<0x92>', '<0x80>']
```
---

### Input:
`https://github.com/Avinash-MiniLLM?tab=repos`

**Unigram:**
```
['http', 's', '://', 'gi', 'th', 'ub', '.', 'com', '/', 'A', 'vin', 'ash', '-', 'M', 'ini', 'LL', 'M', '?', 'tab', '=', 're', 'pos']
```

**BPE:**
```
['htt', 'ps', '://', 'g', 'ith', 'ub', '.', 'com', '/', 'A', 'vin', 'ash', '-', 'M', 'ini', 'LL', 'M', '?', 't', 'ab', '=', 'rep', 'os']
```
---

### Input:
`The quick brown fox jumps over the lazy dog.`

**Unigram:**
```
['The', 'â–quick', 'â–brown', 'â–fox', 'â–jump', 's', 'â–over', 'â–the', 'â–lazy', 'â–dog', '.']
```

**BPE:**
```
['The', 'â–quick', 'â–brown', 'â–fox', 'â–jumps', 'â–over', 'â–the', 'â–l', 'azy', 'â–dog', '.']
```
---

### Input:
`function computeHash(input: bytes): uint256 { return keccak256(input); }`

**Unigram:**
```
['function', 'â–compute', 'H', 'ash', '(', 'in', 'put', ':', 'â–by', 'tes', '):', 'â–u', 'int', '2', '56', 'â–', '{', 'â–return', 'â–ke', 'cc', 'ak', '2', '56', '(', 'in', 'put', ');', 'â–', '}']
```

**BPE:**
```
['function', 'â–comp', 'ute', 'H', 'ash', '(', 'in', 'put', ':', 'â–by', 'tes', '):', 'â–u', 'int', '25', '6', 'â–', '{', 'â–return', 'â–k', 'ec', 'c', 'ak', '25', '6', '(', 'in', 'put', ');', 'â–', '}']
```
---

### Input:
`à¤­à¤¾à¤°à¤¤ is a country â€” multilingual test ğŸŒ`

**Unigram:**
```
['à¤­', 'à¤¾', 'à¤°', 'à¤¤', 'â–is', 'â–a', 'â–country', 'â–â€”', 'â–multi', 'ling', 'ual', 'â–test', 'â–', 'ğŸŒ']
```

**BPE:**
```
['à¤­', 'à¤¾', 'à¤°', 'à¤¤', 'â–is', 'â–a', 'â–country', 'â–â€”', 'â–mult', 'ilingual', 'â–test', 'â–', '<0xF0>', '<0x9F>', '<0x8C>', '<0x8F>']
```
---

## âš™ï¸ Compression Ratios

| Text | Unigram | BPE |
|------|---------|-----|

| `Hello world! <user> write...` | 3.18 | 3.18 |

| `myHTTPRequestHandler is c...` | 2.78 | 2.50 |

| `methylphenidate hydrochlo...` | 3.87 | 3.22 |

| `hello ğŸ”¥ğŸ”¥ğŸ”¥ğŸ’€ğŸ’€...` | 5.20 | 1.08 |

| `https://github.com/Avinas...` | 1.91 | 1.83 |

| `The quick brown fox jumps...` | 3.67 | 3.67 |

| `function computeHash(inpu...` | 2.40 | 2.25 |

| `à¤­à¤¾à¤°à¤¤ is a country â€” multi...` | 3.47 | 3.06 |

---

## ğŸ“Š Vocabulary Usage on Sample Corpus

- **Unigram unique tokens used:** 3668
- **BPE unique tokens used:** 3881

### Unused Vocabulary

- Unigram unused tokens: 9733 (30.42%)
- BPE unused tokens: 9664 (30.20%)
---

## ğŸ”¥ Byte Fallback Behavior

### Input:
```
hello ğŸ”¥ğŸ”¥ğŸ”¥ğŸ’€ğŸ’€
```

**Unigram:**
```
['h', 'ello', 'â–', 'ğŸ”¥ğŸ”¥ğŸ”¥ğŸ’€ğŸ’€']
```

**BPE:**
```
['hell', 'o', 'â–', '<0xF0>', '<0x9F>', '<0x94>', '<0xA5>', '<0xF0>', '<0x9F>', '<0x94>', '<0xA5>', '<0xF0>', '<0x9F>', '<0x94>', '<0xA5>', '<0xF0>', '<0x9F>', '<0x92>', '<0x80>', '<0xF0>', '<0x9F>', '<0x92>', '<0x80>']
```

(Shows why BPE is required for modern LLMs.)

---

## ğŸŒ URL Handling

### Input:
```
https://github.com/Avinash-MiniLLM?tab=repos
```

**Unigram:**
```
['http', 's', '://', 'gi', 'th', 'ub', '.', 'com', '/', 'A', 'vin', 'ash', '-', 'M', 'ini', 'LL', 'M', '?', 'tab', '=', 're', 'pos']
```

**BPE:**
```
['htt', 'ps', '://', 'g', 'ith', 'ub', '.', 'com', '/', 'A', 'vin', 'ash', '-', 'M', 'ini', 'LL', 'M', '?', 't', 'ab', '=', 'rep', 'os']
```

---

## âœ… Summary


- **BPE handles emojis, URLs, code, and multilingual text much better.**
- **Unigram produces <unk> & unstable splits on web-style inputs.**
- BPE matches **Qwen / GPT / OLMo / LLaMA-3** tokenizer behavior.
- Unigram can still be kept for research baselines.

**Recommendation:**  
â¡ï¸ Use **BPE** as primary tokenizer for your 80M Mini-LLM.  
â¡ï¸ Keep Unigram as comparison baseline only.

### Interpretation:
Unigram collapses multi-byte emojis into a single unknown cluster, which breaks consistency.
BPE cleanly decomposes multi-byte UTF-8 sequences, ensuring stable embeddings and preventing <unk> spikes.
This behavior is crucial for modern LLMs handling web, logs, chats, and social text.